{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(3)\n",
      "Box(2,)\n",
      "[0.6  0.07]\n",
      "[-1.2  -0.07]\n",
      "WARNING:tensorflow:From C:\\Users\\xiongan2\\workspace\\ML\\ReinforementLearning\\Ch04_PolicyGradient\\RL_brain.py:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From c:\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "episode: 0   reward: -40467\n",
      "episode: 1   reward: -40205\n",
      "episode: 2   reward: -39994\n",
      "episode: 3   reward: -39636\n",
      "episode: 4   reward: -39351\n",
      "episode: 5   reward: -38999\n",
      "episode: 6   reward: -38678\n",
      "episode: 7   reward: -38374\n",
      "episode: 8   reward: -38030\n",
      "episode: 9   reward: -37665\n",
      "episode: 10   reward: -37338\n",
      "episode: 11   reward: -36984\n",
      "episode: 12   reward: -36636\n",
      "episode: 13   reward: -36285\n",
      "episode: 14   reward: -35955\n",
      "episode: 15   reward: -35623\n",
      "episode: 16   reward: -35285\n",
      "episode: 17   reward: -35010\n",
      "episode: 18   reward: -34745\n",
      "episode: 19   reward: -34482\n",
      "episode: 20   reward: -34187\n",
      "episode: 21   reward: -33919\n",
      "episode: 22   reward: -33587\n",
      "episode: 23   reward: -33317\n",
      "episode: 24   reward: -33024\n",
      "episode: 25   reward: -32727\n",
      "episode: 26   reward: -32470\n",
      "episode: 27   reward: -32220\n",
      "episode: 28   reward: -31943\n",
      "episode: 29   reward: -31657\n",
      "episode: 30   reward: -31438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 31   reward: -31151\n",
      "episode: 32   reward: -30898\n",
      "episode: 33   reward: -30606\n",
      "episode: 34   reward: -30328\n",
      "episode: 35   reward: -30051\n",
      "episode: 36   reward: -29773\n",
      "episode: 37   reward: -29485\n",
      "episode: 38   reward: -29216\n",
      "episode: 39   reward: -28938\n",
      "episode: 40   reward: -28671\n",
      "episode: 41   reward: -28398\n",
      "episode: 42   reward: -28136\n",
      "episode: 43   reward: -27875\n",
      "episode: 44   reward: -27620\n",
      "episode: 45   reward: -27364\n",
      "episode: 46   reward: -27113\n",
      "episode: 47   reward: -26854\n",
      "episode: 48   reward: -26685\n",
      "episode: 49   reward: -26472\n",
      "episode: 50   reward: -26262\n",
      "episode: 51   reward: -26081\n",
      "episode: 52   reward: -25852\n",
      "episode: 53   reward: -25638\n",
      "episode: 54   reward: -25407\n",
      "episode: 55   reward: -25184\n",
      "episode: 56   reward: -24984\n",
      "episode: 57   reward: -24750\n",
      "episode: 58   reward: -24525\n",
      "episode: 59   reward: -24337\n",
      "episode: 60   reward: -24111\n",
      "episode: 61   reward: -23912\n",
      "episode: 62   reward: -23696\n",
      "episode: 63   reward: -23486\n",
      "episode: 64   reward: -23284\n",
      "episode: 65   reward: -23083\n",
      "episode: 66   reward: -22872\n",
      "episode: 67   reward: -22653\n",
      "episode: 68   reward: -22450\n",
      "episode: 69   reward: -22233\n",
      "episode: 70   reward: -22020\n",
      "episode: 71   reward: -21846\n",
      "episode: 72   reward: -21651\n",
      "episode: 73   reward: -21472\n",
      "episode: 74   reward: -21268\n",
      "episode: 75   reward: -21067\n",
      "episode: 76   reward: -20868\n",
      "episode: 77   reward: -20682\n",
      "episode: 78   reward: -20494\n",
      "episode: 79   reward: -20318\n",
      "episode: 80   reward: -20143\n",
      "episode: 81   reward: -19961\n",
      "episode: 82   reward: -19783\n",
      "episode: 83   reward: -19618\n",
      "episode: 84   reward: -19446\n",
      "episode: 85   reward: -19262\n",
      "episode: 86   reward: -19094\n",
      "episode: 87   reward: -18923\n",
      "episode: 88   reward: -18752\n",
      "episode: 89   reward: -18594\n",
      "episode: 90   reward: -18426\n",
      "episode: 91   reward: -18310\n",
      "episode: 92   reward: -18152\n",
      "episode: 93   reward: -18003\n",
      "episode: 94   reward: -17884\n",
      "episode: 95   reward: -17753\n",
      "episode: 96   reward: -17596\n",
      "episode: 97   reward: -17462\n",
      "episode: 98   reward: -17319\n",
      "episode: 99   reward: -17176\n",
      "episode: 100   reward: -17020\n",
      "episode: 101   reward: -16889\n",
      "episode: 102   reward: -16761\n",
      "episode: 103   reward: -16608\n",
      "episode: 104   reward: -16462\n",
      "episode: 105   reward: -16321\n",
      "episode: 106   reward: -16182\n",
      "episode: 107   reward: -16064\n",
      "episode: 108   reward: -15922\n",
      "episode: 109   reward: -15779\n",
      "episode: 110   reward: -15642\n",
      "episode: 111   reward: -15492\n",
      "episode: 112   reward: -15356\n",
      "episode: 113   reward: -15225\n",
      "episode: 114   reward: -15090\n",
      "episode: 115   reward: -14951\n",
      "episode: 116   reward: -14820\n",
      "episode: 117   reward: -14689\n",
      "episode: 118   reward: -14554\n",
      "episode: 119   reward: -14423\n",
      "episode: 120   reward: -14313\n",
      "episode: 121   reward: -14202\n",
      "episode: 122   reward: -14090\n",
      "episode: 123   reward: -13974\n",
      "episode: 124   reward: -13859\n",
      "episode: 125   reward: -13733\n",
      "episode: 126   reward: -13625\n",
      "episode: 127   reward: -13506\n",
      "episode: 128   reward: -13412\n",
      "episode: 129   reward: -13287\n",
      "episode: 130   reward: -13167\n",
      "episode: 131   reward: -13073\n",
      "episode: 132   reward: -12953\n",
      "episode: 133   reward: -12850\n",
      "episode: 134   reward: -12733\n",
      "episode: 135   reward: -12622\n",
      "episode: 136   reward: -12520\n",
      "episode: 137   reward: -12409\n",
      "episode: 138   reward: -12295\n",
      "episode: 139   reward: -12183\n",
      "episode: 140   reward: -12079\n",
      "episode: 141   reward: -11986\n",
      "episode: 142   reward: -11880\n",
      "episode: 143   reward: -11786\n",
      "episode: 144   reward: -11687\n",
      "episode: 145   reward: -11580\n",
      "episode: 146   reward: -11475\n",
      "episode: 147   reward: -11369\n",
      "episode: 148   reward: -11264\n",
      "episode: 149   reward: -11157\n",
      "episode: 150   reward: -11052\n",
      "episode: 151   reward: -10948\n",
      "episode: 152   reward: -10845\n",
      "episode: 153   reward: -10746\n",
      "episode: 154   reward: -10653\n",
      "episode: 155   reward: -10558\n",
      "episode: 156   reward: -10456\n",
      "episode: 157   reward: -10357\n",
      "episode: 158   reward: -10263\n",
      "episode: 159   reward: -10170\n",
      "episode: 160   reward: -10073\n",
      "episode: 161   reward: -9978\n",
      "episode: 162   reward: -9887\n",
      "episode: 163   reward: -9793\n",
      "episode: 164   reward: -9705\n",
      "episode: 165   reward: -9622\n",
      "episode: 166   reward: -9537\n",
      "episode: 167   reward: -9451\n",
      "episode: 168   reward: -9364\n",
      "episode: 169   reward: -9285\n",
      "episode: 170   reward: -9201\n",
      "episode: 171   reward: -9123\n",
      "episode: 172   reward: -9048\n",
      "episode: 173   reward: -8973\n",
      "episode: 174   reward: -8896\n",
      "episode: 175   reward: -8827\n",
      "episode: 176   reward: -8759\n",
      "episode: 177   reward: -8678\n",
      "episode: 178   reward: -8601\n",
      "episode: 179   reward: -8527\n",
      "episode: 180   reward: -8450\n",
      "episode: 181   reward: -8383\n",
      "episode: 182   reward: -8324\n",
      "episode: 183   reward: -8267\n",
      "episode: 184   reward: -8195\n",
      "episode: 185   reward: -8134\n",
      "episode: 186   reward: -8065\n",
      "episode: 187   reward: -7995\n",
      "episode: 188   reward: -7928\n",
      "episode: 189   reward: -7856\n",
      "episode: 190   reward: -7787\n",
      "episode: 191   reward: -7720\n",
      "episode: 192   reward: -7653\n",
      "episode: 193   reward: -7583\n",
      "episode: 194   reward: -7517\n",
      "episode: 195   reward: -7451\n",
      "episode: 196   reward: -7392\n",
      "episode: 197   reward: -7328\n",
      "episode: 198   reward: -7279\n",
      "episode: 199   reward: -7220\n",
      "episode: 200   reward: -7157\n",
      "episode: 201   reward: -7091\n",
      "episode: 202   reward: -7029\n",
      "episode: 203   reward: -6970\n",
      "episode: 204   reward: -6908\n",
      "episode: 205   reward: -6862\n",
      "episode: 206   reward: -6806\n",
      "episode: 207   reward: -6744\n",
      "episode: 208   reward: -6689\n",
      "episode: 209   reward: -6633\n",
      "episode: 210   reward: -6593\n",
      "episode: 211   reward: -6536\n",
      "episode: 212   reward: -6489\n",
      "episode: 213   reward: -6442\n",
      "episode: 214   reward: -6401\n",
      "episode: 215   reward: -6353\n",
      "episode: 216   reward: -6320\n",
      "episode: 217   reward: -6270\n",
      "episode: 218   reward: -6222\n",
      "episode: 219   reward: -6176\n",
      "episode: 220   reward: -6139\n",
      "episode: 221   reward: -6094\n",
      "episode: 222   reward: -6046\n",
      "episode: 223   reward: -6004\n",
      "episode: 224   reward: -5958\n",
      "episode: 225   reward: -5907\n",
      "episode: 226   reward: -5884\n",
      "episode: 227   reward: -5846\n",
      "episode: 228   reward: -5804\n",
      "episode: 229   reward: -5762\n",
      "episode: 230   reward: -5720\n",
      "episode: 231   reward: -5682\n",
      "episode: 232   reward: -5649\n",
      "episode: 233   reward: -5610\n",
      "episode: 234   reward: -5579\n",
      "episode: 235   reward: -5535\n",
      "episode: 236   reward: -5520\n",
      "episode: 237   reward: -5509\n",
      "episode: 238   reward: -5482\n",
      "episode: 239   reward: -5451\n",
      "episode: 240   reward: -5434\n",
      "episode: 241   reward: -5451\n",
      "episode: 242   reward: -5423\n",
      "episode: 243   reward: -5408\n",
      "episode: 244   reward: -5417\n",
      "episode: 245   reward: -5395\n",
      "episode: 246   reward: -5375\n",
      "episode: 247   reward: -5345\n",
      "episode: 248   reward: -5308\n",
      "episode: 249   reward: -5279\n",
      "episode: 250   reward: -5269\n",
      "episode: 251   reward: -5248\n",
      "episode: 252   reward: -5238\n",
      "episode: 253   reward: -5216\n",
      "episode: 254   reward: -5202\n",
      "episode: 255   reward: -5169\n",
      "episode: 256   reward: -5160\n",
      "episode: 257   reward: -5135\n",
      "episode: 258   reward: -5131\n",
      "episode: 259   reward: -5119\n",
      "episode: 260   reward: -5090\n",
      "episode: 261   reward: -5062\n",
      "episode: 262   reward: -5035\n",
      "episode: 263   reward: -5006\n",
      "episode: 264   reward: -4974\n",
      "episode: 265   reward: -4950\n",
      "episode: 266   reward: -4943\n",
      "episode: 267   reward: -4959\n",
      "episode: 268   reward: -4938\n",
      "episode: 269   reward: -4908\n",
      "episode: 270   reward: -4905\n",
      "episode: 271   reward: -4883\n",
      "episode: 272   reward: -4860\n",
      "episode: 273   reward: -4844\n",
      "episode: 274   reward: -4821\n",
      "episode: 275   reward: -4801\n",
      "episode: 276   reward: -4802\n",
      "episode: 277   reward: -4798\n",
      "episode: 278   reward: -4803\n",
      "episode: 279   reward: -4799\n",
      "episode: 280   reward: -4770\n",
      "episode: 281   reward: -4738\n",
      "episode: 282   reward: -4727\n",
      "episode: 283   reward: -4708\n",
      "episode: 284   reward: -4684\n",
      "episode: 285   reward: -4658\n",
      "episode: 286   reward: -4650\n",
      "episode: 287   reward: -4633\n",
      "episode: 288   reward: -4611\n",
      "episode: 289   reward: -4580\n",
      "episode: 290   reward: -4576\n",
      "episode: 291   reward: -4572\n",
      "episode: 292   reward: -4540\n",
      "episode: 293   reward: -4542\n",
      "episode: 294   reward: -4541\n",
      "episode: 295   reward: -4519\n",
      "episode: 296   reward: -4484\n",
      "episode: 297   reward: -4449\n",
      "episode: 298   reward: -4419\n",
      "episode: 299   reward: -4398\n",
      "episode: 300   reward: -4381\n",
      "episode: 301   reward: -4350\n",
      "episode: 302   reward: -4319\n",
      "episode: 303   reward: -4305\n",
      "episode: 304   reward: -4284\n",
      "episode: 305   reward: -4263\n",
      "episode: 306   reward: -4245\n",
      "episode: 307   reward: -4212\n",
      "episode: 308   reward: -4197\n",
      "episode: 309   reward: -4192\n",
      "episode: 310   reward: -4159\n",
      "episode: 311   reward: -4136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 312   reward: -4107\n",
      "episode: 313   reward: -4078\n",
      "episode: 314   reward: -4046\n",
      "episode: 315   reward: -4017\n",
      "episode: 316   reward: -3985\n",
      "episode: 317   reward: -3953\n",
      "episode: 318   reward: -3924\n",
      "episode: 319   reward: -3891\n",
      "episode: 320   reward: -3859\n",
      "episode: 321   reward: -3831\n",
      "episode: 322   reward: -3797\n",
      "episode: 323   reward: -3769\n",
      "episode: 324   reward: -3742\n",
      "episode: 325   reward: -3713\n",
      "episode: 326   reward: -3682\n",
      "episode: 327   reward: -3649\n",
      "episode: 328   reward: -3618\n",
      "episode: 329   reward: -3588\n",
      "episode: 330   reward: -3558\n",
      "episode: 331   reward: -3527\n",
      "episode: 332   reward: -3495\n",
      "episode: 333   reward: -3469\n",
      "episode: 334   reward: -3453\n",
      "episode: 335   reward: -3430\n",
      "episode: 336   reward: -3409\n",
      "episode: 337   reward: -3385\n",
      "episode: 338   reward: -3365\n",
      "episode: 339   reward: -3338\n",
      "episode: 340   reward: -3311\n",
      "episode: 341   reward: -3282\n",
      "episode: 342   reward: -3253\n",
      "episode: 343   reward: -3229\n",
      "episode: 344   reward: -3207\n",
      "episode: 345   reward: -3180\n",
      "episode: 346   reward: -3154\n",
      "episode: 347   reward: -3125\n",
      "episode: 348   reward: -3098\n",
      "episode: 349   reward: -3070\n",
      "episode: 350   reward: -3043\n",
      "episode: 351   reward: -3015\n",
      "episode: 352   reward: -2988\n",
      "episode: 353   reward: -2961\n",
      "episode: 354   reward: -2935\n",
      "episode: 355   reward: -2914\n",
      "episode: 356   reward: -2892\n",
      "episode: 357   reward: -3064\n",
      "episode: 358   reward: -3126\n",
      "episode: 359   reward: -3107\n",
      "episode: 360   reward: -3102\n",
      "episode: 361   reward: -3089\n",
      "episode: 362   reward: -3067\n",
      "episode: 363   reward: -3040\n",
      "episode: 364   reward: -3014\n",
      "episode: 365   reward: -2987\n",
      "episode: 366   reward: -2959\n",
      "episode: 367   reward: -2932\n",
      "episode: 368   reward: -2907\n",
      "episode: 369   reward: -2880\n",
      "episode: 370   reward: -2855\n",
      "episode: 371   reward: -2829\n",
      "episode: 372   reward: -2804\n",
      "episode: 373   reward: -2780\n",
      "episode: 374   reward: -2755\n",
      "episode: 375   reward: -2732\n",
      "episode: 376   reward: -2708\n",
      "episode: 377   reward: -2684\n",
      "episode: 378   reward: -2665\n",
      "episode: 379   reward: -2644\n",
      "episode: 380   reward: -2623\n",
      "episode: 381   reward: -2603\n",
      "episode: 382   reward: -2580\n",
      "episode: 383   reward: -2558\n",
      "episode: 384   reward: -2537\n",
      "episode: 385   reward: -2516\n",
      "episode: 386   reward: -2496\n",
      "episode: 387   reward: -2474\n",
      "episode: 388   reward: -2451\n",
      "episode: 389   reward: -2430\n",
      "episode: 390   reward: -2408\n",
      "episode: 391   reward: -2387\n",
      "episode: 392   reward: -2367\n",
      "episode: 393   reward: -2347\n",
      "episode: 394   reward: -2327\n",
      "episode: 395   reward: -2308\n",
      "episode: 396   reward: -2288\n",
      "episode: 397   reward: -2268\n",
      "episode: 398   reward: -2248\n",
      "episode: 399   reward: -2228\n",
      "episode: 400   reward: -2210\n",
      "episode: 401   reward: -2190\n",
      "episode: 402   reward: -2171\n",
      "episode: 403   reward: -2151\n",
      "episode: 404   reward: -2133\n",
      "episode: 405   reward: -2117\n",
      "episode: 406   reward: -2099\n",
      "episode: 407   reward: -2081\n",
      "episode: 408   reward: -2062\n",
      "episode: 409   reward: -2045\n",
      "episode: 410   reward: -2028\n",
      "episode: 411   reward: -2011\n",
      "episode: 412   reward: -1994\n",
      "episode: 413   reward: -1978\n",
      "episode: 414   reward: -1962\n",
      "episode: 415   reward: -1946\n",
      "episode: 416   reward: -1931\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from RL_brain import PolicyGradient\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DISPLAY_REWARD_THRESHOLD = -2000  # renders environment if total episode reward is greater then this threshold\n",
    "# episode: 154   reward: -10667\n",
    "# episode: 387   reward: -2009\n",
    "# episode: 489   reward: -1006\n",
    "# episode: 628   reward: -502\n",
    "\n",
    "RENDER = False  # rendering wastes time\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "env.seed(1)     # reproducible, general Policy gradient has high variance\n",
    "env = env.unwrapped\n",
    "\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)\n",
    "\n",
    "RL = PolicyGradient(\n",
    "    n_actions=env.action_space.n,\n",
    "    n_features=env.observation_space.shape[0],\n",
    "    learning_rate=0.02,\n",
    "    reward_decay=0.995,\n",
    "    # output_graph=True,\n",
    ")\n",
    "\n",
    "for i_episode in range(1000):\n",
    "\n",
    "    observation = env.reset()\n",
    "\n",
    "    while True:\n",
    "        if RENDER: env.render()\n",
    "\n",
    "        action = RL.choose_action(observation)\n",
    "\n",
    "        observation_, reward, done, info = env.step(action)     # reward = -1 in all cases\n",
    "\n",
    "        RL.store_transition(observation, action, reward)\n",
    "\n",
    "        if done:\n",
    "            # calculate running reward\n",
    "            ep_rs_sum = sum(RL.ep_rs)\n",
    "            if 'running_reward' not in globals():\n",
    "                running_reward = ep_rs_sum\n",
    "            else:\n",
    "                running_reward = running_reward * 0.99 + ep_rs_sum * 0.01\n",
    "            if running_reward > DISPLAY_REWARD_THRESHOLD: RENDER = True     # rendering\n",
    "\n",
    "            print(\"episode:\", i_episode, \"  reward:\", int(running_reward))\n",
    "\n",
    "            vt = RL.learn()  # train\n",
    "\n",
    "            if i_episode == 30:\n",
    "                plt.plot(vt)  # plot the episode vt\n",
    "                plt.xlabel('episode steps')\n",
    "                plt.ylabel('normalized state-action value')\n",
    "                plt.show()\n",
    "\n",
    "            break\n",
    "\n",
    "        observation = observation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
